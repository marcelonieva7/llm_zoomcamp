{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9a3060f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fast language models are crucial in today's world of natural language processing (NLP) for several reasons:\n",
      "\n",
      "1. **Efficient Processing**: Fast language models can process and analyze large amounts of text data quickly, making them ideal for applications that require real-time or near-real-time processing. This is particularly important for tasks such as sentiment analysis, entity recognition, and language translation.\n",
      "2. **Improved User Experience**: Fast language models enable applications to respond quickly to user input, providing a seamless and interactive experience. This is especially important for chatbots, virtual assistants, and other conversational AI systems.\n",
      "3. **Scalability**: Fast language models can handle a large volume of requests and process them quickly, making them scalable for large-scale applications. This is critical for industries such as customer service, where a large number of customers may be interacting with a chatbot or virtual assistant simultaneously.\n",
      "4. **Reduced Latency**: Fast language models minimize latency, which is the delay between the time a user inputs text and the time the model responds. Reduced latency is essential for applications that require immediate feedback, such as real-time language translation or sentiment analysis.\n",
      "5. **Energy Efficiency**: Fast language models can be more energy-efficient than slower models, as they\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "from groq import Groq\n",
    "\n",
    "import os\n",
    "\n",
    "load_dotenv('../.env')\n",
    "\n",
    "\n",
    "client = Groq(\n",
    "  api_key=os.getenv(\"GROQ_API_KEY\")\n",
    ")\n",
    "\n",
    "MODEL = \"llama-3.3-70b-versatile\"\n",
    "\n",
    "# test Groq connection\n",
    "chat_completion = client.chat.completions.create(\n",
    "  messages=[\n",
    "  {\n",
    "    \"role\": \"system\",\n",
    "    \"content\": \"You are a helpful assistant.\"\n",
    "  },\n",
    "  {\n",
    "    \"role\": \"user\",\n",
    "    \"content\": \"Explain the importance of fast language models\",\n",
    "  }\n",
    "  ],\n",
    "  model=MODEL,\n",
    "  max_completion_tokens=250\n",
    ")\n",
    "\n",
    "print(chat_completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "6288216c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "response ChatCompletion(id='chatcmpl-3c689a49-e9d8-4379-b6d3-7bfab7cb6c1b', choices=[Choice(finish_reason='tool_calls', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', executed_tools=None, function_call=None, reasoning=None, tool_calls=[ChatCompletionMessageToolCall(id='yhrsr6ktz', function=Function(arguments='{\"city\":\"Berlin\"}', name='get_weather'), type='function')]))], created=1752563883, model='llama-3.3-70b-versatile', object='chat.completion', system_fingerprint='fp_6507bcfb6f', usage=CompletionUsage(completion_tokens=14, prompt_tokens=268, total_tokens=282, completion_time=0.032647786, prompt_time=0.021502746, queue_time=0.27360635699999997, total_time=0.054150532), usage_breakdown=None, x_groq={'id': 'req_01k06f56v9ecyb360kfbjegsd6'}, service_tier='on_demand')\n",
      "second_response ChatCompletion(id='chatcmpl-1a5dc82f-0063-4b84-a3ae-71fe3e5f0680', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='The current weather in Berlin is partly cloudy with a temperature of 20.0°C.', role='assistant', executed_tools=None, function_call=None, reasoning=None, tool_calls=None))], created=1752563883, model='llama-3.3-70b-versatile', object='chat.completion', system_fingerprint='fp_6507bcfb6f', usage=CompletionUsage(completion_tokens=19, prompt_tokens=92, total_tokens=111, completion_time=0.034417724, prompt_time=0.012015403, queue_time=0.27330553100000005, total_time=0.046433127), usage_breakdown=None, x_groq={'id': 'req_01k06f57d6ecy9stakmsnecgw3'}, service_tier='on_demand')\n",
      "The current weather in Berlin is partly cloudy with a temperature of 20.0°C.\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import json\n",
    "\n",
    "known_weather_data = {\n",
    "  'berlin': 20.0\n",
    "}\n",
    "\n",
    "def get_weather(city: str) -> float:\n",
    "  city = city.strip().lower()\n",
    "\n",
    "  if city in known_weather_data:\n",
    "      return known_weather_data[city]\n",
    "\n",
    "  return round(random.uniform(-5, 35), 1)\n",
    "\n",
    "get_weather_tool = {\n",
    "    \"type\": \"function\",\n",
    "    \"function\": {\n",
    "        \"name\": \"get_weather\",\n",
    "        \"description\": \"Retrieves the temperature for a specified city.\",\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "            \"city\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"The name of the city, e.g. New York\"\n",
    "            }\n",
    "            },\n",
    "            \"required\": [\"city\"],\n",
    "            \"additionalProperties\": False\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "# imports calculate function from step 1\n",
    "def run_conversation(user_prompt):\n",
    "    # Initialize the conversation with system and user messages\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"You are a weather assistant. Use the get weather function to get the weather for a given city and provide the results.\"\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": user_prompt,\n",
    "        }\n",
    "    ]\n",
    "    # Define the available tools (i.e. functions) for our model to use\n",
    "    tools = [get_weather_tool]\n",
    "    # Make the initial API call to Groq\n",
    "    response = client.chat.completions.create(\n",
    "        model=MODEL, # LLM to use\n",
    "        messages=messages, # Conversation history\n",
    "        stream=False,\n",
    "        tools=tools, # Available tools (i.e. functions) for our LLM to use\n",
    "        tool_choice=\"auto\", # Let our LLM decide when to use tools\n",
    "        max_completion_tokens=4096 # Maximum number of tokens to allow in our response\n",
    "    )\n",
    "    print(\"response\", response)\n",
    "    # Extract the response and any tool call responses\n",
    "    response_message = response.choices[0].message\n",
    "    tool_calls = response_message.tool_calls\n",
    "    if tool_calls:\n",
    "        # Define the available tools that can be called by the LLM\n",
    "        available_functions = {\n",
    "            \"get_weather\": get_weather,\n",
    "        }\n",
    "        # Add the LLM's response to the conversation\n",
    "        messages.append(response_message)\n",
    "\n",
    "        # Process each tool call\n",
    "        for tool_call in tool_calls:\n",
    "            function_name = tool_call.function.name\n",
    "            function_to_call = available_functions[function_name]\n",
    "            function_args = json.loads(tool_call.function.arguments)\n",
    "            # Call the tool and get the response\n",
    "            function_response = function_to_call(\n",
    "                city=function_args.get(\"city\")\n",
    "            )\n",
    "            function_response = str(function_response)\n",
    "            # Add the tool response to the conversation\n",
    "            messages.append(\n",
    "                {\n",
    "                    \"tool_call_id\": tool_call.id, \n",
    "                    \"role\": \"tool\", # Indicates this message is from tool use\n",
    "                    \"name\": function_name,\n",
    "                    \"content\": function_response,\n",
    "                }\n",
    "            )\n",
    "        # Make a second API call with the updated conversation\n",
    "        second_response = client.chat.completions.create(\n",
    "            model=MODEL,\n",
    "            messages=messages\n",
    "        )\n",
    "        print(\"second_response\", second_response)\n",
    "        # Return the final response\n",
    "        return second_response.choices[0].message.content\n",
    "# Example usage\n",
    "user_prompt = \"What is the weather in berlin?\"\n",
    "print(run_conversation(user_prompt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "01073c93",
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "\n",
    "importlib.reload(chat_assistant)\n",
    "import chat_assistant\n",
    "\n",
    "\n",
    "tools = chat_assistant.Tools()\n",
    "tools.add_tool(get_weather, get_weather_tool)\n",
    "\n",
    "developer_prompt = \"\"\"\n",
    "You are a weather assistant. Use the get weather function to get the weather for a given city and provide the results.\n",
    "Use the set weather function to set the weather for a given city.\n",
    "If not city name is provided, return 'No city name provided'.\n",
    "\"\"\".strip()\n",
    "\n",
    "chat_interface = chat_assistant.ChatInterface()\n",
    "\n",
    "chat = chat_assistant.ChatAssistant(\n",
    "    tools=tools,\n",
    "    developer_prompt=developer_prompt,\n",
    "    chat_interface=chat_interface,\n",
    "    client=client,\n",
    "    model=MODEL\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "9523990a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <div><b>Assistant:</b></div>\n",
       "                <div><p>No city name provided</p></div>\n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <div><b>Assistant:</b></div>\n",
       "                <div><p>No city name provided</p></div>\n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "            <details>\n",
       "            <summary>Function call: <tt>get_weather({\"city\":\"Poman\"})</tt></summary>\n",
       "            <div>\n",
       "                <b>Call</b>\n",
       "                <pre>ChatCompletionMessageToolCall(id='9fc2rjsxw', function=Function(arguments='{\"city\":\"Poman\"}', name='get_weather'), type='function')</pre>\n",
       "            </div>\n",
       "            <div>\n",
       "                <b>Output</b>\n",
       "                <pre>0.8</pre>\n",
       "            </div>\n",
       "            \n",
       "            </details>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "            <details>\n",
       "            <summary>Function call: <tt>get_weather({\"city\":\"Poman\"})</tt></summary>\n",
       "            <div>\n",
       "                <b>Call</b>\n",
       "                <pre>ChatCompletionMessageToolCall(id='4kk4d7m7m', function=Function(arguments='{\"city\":\"Poman\"}', name='get_weather'), type='function')</pre>\n",
       "            </div>\n",
       "            <div>\n",
       "                <b>Output</b>\n",
       "                <pre>10.5</pre>\n",
       "            </div>\n",
       "            \n",
       "            </details>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <div><b>Assistant:</b></div>\n",
       "                <div><p>The weather in Poman is 10.5 degrees.</p></div>\n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chat ended.\n"
     ]
    }
   ],
   "source": [
    "chat.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "c26f6cc7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'type': 'function',\n",
       "  'function': {'name': 'get_weather',\n",
       "   'description': 'Retrieves the temperature for a specified city.',\n",
       "   'parameters': {'type': 'object',\n",
       "    'properties': {'city': {'type': 'string',\n",
       "      'description': 'The name of the city, e.g. New York'}},\n",
       "    'required': ['city'],\n",
       "    'additionalProperties': False}}},\n",
       " {'type': 'function',\n",
       "  'function': {'name': 'set_weather',\n",
       "   'description': 'Sets the temperature for a specified city.',\n",
       "   'parameters': {'type': 'object',\n",
       "    'properties': {'city': {'type': 'string',\n",
       "      'description': 'The name of the city, e.g. New York'},\n",
       "     'temp': {'type': 'number',\n",
       "      'description': 'The temperature to associate with the city, e.g. 20'}},\n",
       "    'required': ['city', 'temp'],\n",
       "    'additionalProperties': False}}}]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def set_weather(city: str, temp: float) -> None:\n",
    "  city = city.strip().lower()\n",
    "  known_weather_data[city] = temp\n",
    "  return 'OK'\n",
    "\n",
    "set_weather_tool = {\n",
    "  \"type\": \"function\",\n",
    "  \"function\": {\n",
    "    \"name\": \"set_weather\",\n",
    "    \"description\": \"Sets the temperature for a specified city.\",\n",
    "    \"parameters\": {\n",
    "      \"type\": \"object\",\n",
    "      \"properties\": {\n",
    "        \"city\": {\n",
    "          \"type\": \"string\",\n",
    "          \"description\": \"The name of the city, e.g. New York\"\n",
    "        },\n",
    "        \"temp\": {\n",
    "          \"type\": \"number\",\n",
    "          \"description\": \"The temperature to associate with the city, e.g. 20\"\n",
    "        }\n",
    "      },\n",
    "      \"required\": [\"city\", \"temp\"],\n",
    "      \"additionalProperties\": False\n",
    "    }\n",
    "  }\n",
    "}\n",
    "\n",
    "tools.add_tool(set_weather, set_weather_tool)\n",
    "\n",
    "tools.get_tools()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "8e659377",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <details>\n",
       "            <summary>Function call: <tt>set_weather({\"city\":\"New York\",\"temp\":33})</tt></summary>\n",
       "            <div>\n",
       "                <b>Call</b>\n",
       "                <pre>ChatCompletionMessageToolCall(id='nxbzre5pm', function=Function(arguments='{\"city\":\"New York\",\"temp\":33}', name='set_weather'), type='function')</pre>\n",
       "            </div>\n",
       "            <div>\n",
       "                <b>Output</b>\n",
       "                <pre>\"OK\"</pre>\n",
       "            </div>\n",
       "            \n",
       "            </details>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <div><b>Assistant:</b></div>\n",
       "                <div><p>The temperature for New York has been set to 33 degrees.</p></div>\n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chat ended.\n"
     ]
    }
   ],
   "source": [
    "chat = chat_assistant.ChatAssistant(\n",
    "    tools=tools,\n",
    "    developer_prompt=developer_prompt,\n",
    "    chat_interface=chat_interface,\n",
    "    client=client,\n",
    "    model=MODEL\n",
    ")\n",
    "chat.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "04f36415",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'berlin': 20.0, 'new york': 33}"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "known_weather_data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
